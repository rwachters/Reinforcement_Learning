{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3D Balance Ball\n",
    "\n",
    "In this notebook, we will run the [3D Balance Ball example](https://github.com/Unity-Technologies/ml-agents/blob/main/docs/Learning-Environment-Examples.md#3dball-3d-balance-ball) from [Unity ML Agents](https://unity.com/products/machine-learning-agents). Please check the README file to setup this project.\n",
    "\n",
    "### 1. Start the Environment\n",
    "\n",
    "We begin by importing the necessary packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from my_unity_environment import MyUnityEnvironment\n",
    "from model import Actor, Critic\n",
    "from ddpg_agents import DDPGAgents\n",
    "from ddpg_agent import DDPGAgent\n",
    "from replay_buffer import ReplayBuffer\n",
    "from utilities import convert_to_tensor\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as f\n",
    "import random\n",
    "from collections import deque\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will start the environment. Before running the code cell below, change the `ENV_FILE_NAME` parameter to match the location of the Unity executable that you [downloaded](README.md) or [created](../README.md#creating-a-custom-unity-executable) yourself. For example:\n",
    "\n",
    "```\n",
    "ENV_FILE_NAME = \"3DBall_Windows_x86_64/UnityEnvironment.exe\"\n",
    "```\n",
    "A new window should pop up. Don't worry if the window becomes unresponsive.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ENV_FILE_NAME = \"3DBall_Windows_x86_64/UnityEnvironment.exe\"\n",
    "CHECKPOINT_FILENAME = \"checkpoint-3dball.pth\" # this is used for saving and loading the model\n",
    "DISPLAY_SIZE = [1024, 768] # The width and height of the Unity window\n",
    "\n",
    "test_env = MyUnityEnvironment(file_name=ENV_FILE_NAME, no_graphics=False)\n",
    "test_env.set_timescale(1.0)\n",
    "test_env.set_display_size(width=DISPLAY_SIZE[0], height=DISPLAY_SIZE[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Examine the State and Action Spaces\n",
    "\n",
    "In this environment, an agent must balance a ball on its head for as long as possible.\n",
    "\n",
    "**Agent Reward Function:**\n",
    "- +0.1 for every step the ball remains on its head.\n",
    "- -1.0 if the ball falls off.\n",
    "\n",
    "**Behavior Parameters:**\n",
    "- Vector Observation space: 8 variables corresponding to rotation of the agent cube, and position and velocity of ball.\n",
    "- Actions: 2 continuous actions, with one value corresponding to X-rotation, and the other to Z-rotation.\n",
    "\n",
    "Run the code cell below to print some information about the environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents: 1\n",
      "Size of each action: 2\n",
      "States look like: [-0.04766776 -0.08700117 -0.54295158  4.          0.11863136  0.\n",
      "  0.          0.        ]\n",
      "States have shape: (8,)\n"
     ]
    }
   ],
   "source": [
    "def examine_environment(myenv: MyUnityEnvironment):\n",
    "    # number of agents in the first behavior:\n",
    "    print('Number of agents:', myenv.num_agents_list[0])\n",
    "\n",
    "    # number of actions\n",
    "    print('Size of each action:', myenv.behavior_specs[0].action_spec.continuous_size)\n",
    "\n",
    "    # examine the state space\n",
    "    print('States look like:', myenv.get_observations(0)[0])\n",
    "    print('States have shape:', myenv.behavior_specs[0].observation_specs[0].shape)\n",
    "\n",
    "examine_environment(test_env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Take Random Actions in the Parallel Environment\n",
    "\n",
    "Run the code cell below, to watch a random agent in action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score from episode 0: 2.0000000447034836\n",
      "Score from episode 1: 1.500000037252903\n",
      "Score from episode 2: 2.400000050663948\n",
      "Score from episode 3: 2.1000000461935997\n",
      "Score from episode 4: 1.2000000327825546\n",
      "Score from episode 5: 2.400000050663948\n",
      "Score from episode 6: 1.0000000298023224\n",
      "Score from episode 7: 1.8000000417232513\n",
      "Score from episode 8: 1.1000000312924385\n",
      "Score from episode 9: 1.1000000312924385\n",
      "Time elapsed: 27.05\n"
     ]
    }
   ],
   "source": [
    "def test_random_agents(myenv: MyUnityEnvironment, n_episodes: int, max_t: int):\n",
    "    start_time = time.time()\n",
    "    for i in range(n_episodes):\n",
    "        myenv.reset()\n",
    "        scores = np.zeros(myenv.num_agents_list[0])\n",
    "        for t in range(max_t):\n",
    "            actions = np.random.randn(myenv.num_agents_list[0],\n",
    "                                      myenv.behavior_specs[0].action_spec.continuous_size)\n",
    "            actions = np.clip(actions, -1, 1)\n",
    "            myenv.set_actions(behavior_index=0, continuous=actions)\n",
    "            myenv.step()\n",
    "            _, rewards, dones = myenv.get_experiences(behavior_index=0)\n",
    "            scores += rewards.squeeze()\n",
    "            if np.any(dones):\n",
    "                break\n",
    "        print('Score from episode {}: {}'.format(i, np.max(scores)))\n",
    "    print(f\"Time elapsed: {time.time() - start_time:.2f}\")\n",
    "\n",
    "test_random_agents(test_env, n_episodes=10, max_t=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "test_env.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 4. Train the Agent with DDPG\n",
    "\n",
    "Run the code cells below to train the agent from scratch.\n",
    "\n",
    "Alternatively, you can skip to the next step below (**5. Watch a Smart Agent**), to load the saved model weights from a pre-trained agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class DDPGAgentsTester:\n",
    "    def __init__(self, ddpg_agents: DDPGAgents,\n",
    "                 myenv: MyUnityEnvironment,\n",
    "                 buffer_size=int(1.0e6),  # replay buffer size\n",
    "                 noise_start=1.0\n",
    "                 ):\n",
    "        self.ddpg_agents = ddpg_agents\n",
    "        self.myenv = myenv\n",
    "        self.buffer_size = buffer_size\n",
    "        self.scores = []\n",
    "        self.scores_deque = deque(maxlen=100)\n",
    "        self.episode = 0\n",
    "        self.noise = noise_start\n",
    "        self.replay_buffer = ReplayBuffer(buffer_size)\n",
    "\n",
    "    def train_agents(self, n_episodes, max_t, goal=float(\"inf\"), print_every=1000, update_every=1,\n",
    "                     num_updates=1, batch_size=64, noise_decay=6.93e-6):\n",
    "        \"\"\" Multi Agent Deep Deterministic Policy Gradient algorithm.\n",
    "\n",
    "        Params\n",
    "        ======\n",
    "            n_episodes (int): maximum number of training episodes\n",
    "            max_t (int): maximum number of timesteps per episode\n",
    "            goal (float): the algorithm will stop when the goal is reached\n",
    "            print_every (int) : print intermediate results every %print_every episodes\n",
    "            update_every (int): update the neural networks every %update_every time steps\n",
    "            num_updates: How many updates to do in a row\n",
    "            batch_size (int): minibatch size\n",
    "            noise_decay (float): noise decay factor = 1.0 - %noise_decay\n",
    "        \"\"\"\n",
    "        noise_decay = 1.0 - noise_decay\n",
    "        start_episode = self.episode\n",
    "        stop_episode = self.episode + n_episodes\n",
    "        steps = 0\n",
    "        start_time = time.time()\n",
    "        last_print_time = 0\n",
    "        for self.episode in range(start_episode, stop_episode):\n",
    "            score = np.zeros(len(self.ddpg_agents))\n",
    "            self.myenv.reset()\n",
    "            states = self.myenv.get_observations(behavior_index=0)\n",
    "            for t in range(max_t):\n",
    "                steps += 1\n",
    "                # get actions from all agents:\n",
    "                actions = self.ddpg_agents.act(convert_to_tensor(states[:, np.newaxis, :]), self.noise)\n",
    "                # remove batch_size from actions:\n",
    "                actions = actions[:, 0, :]\n",
    "                self.myenv.set_actions(behavior_index=0, continuous=actions)\n",
    "                self.myenv.step()\n",
    "                next_states, rewards, dones = self.myenv.get_experiences(behavior_index=0)\n",
    "\n",
    "                # add sample to replay buffer:\n",
    "                sample = (states, actions, rewards, next_states, dones)\n",
    "                self.replay_buffer.add(sample)\n",
    "\n",
    "                states = next_states\n",
    "                self.noise *= noise_decay\n",
    "                score += rewards.squeeze()\n",
    "\n",
    "                # update networks every %update_every time steps:\n",
    "                if steps % update_every == 0 and len(self.replay_buffer) > batch_size * 100:\n",
    "                    for _ in range(num_updates):\n",
    "                        samples = [self.replay_buffer.sample(batch_size) for _ in range(len(self.ddpg_agents))]\n",
    "                        self.ddpg_agents.step(samples)\n",
    "                        #soft update the target network towards the actual networks:\n",
    "                        self.ddpg_agents.update_target_networks()\n",
    "\n",
    "                if np.any(dones):  # exit loop if episode finished\n",
    "                    break\n",
    "\n",
    "            self.scores_deque.append(score)\n",
    "            self.scores.append(score)\n",
    "\n",
    "            average_scores = np.mean(self.scores_deque, 0)  # average score over last 100 episodes for each agent\n",
    "            if time.time() - last_print_time > 1.0:\n",
    "                time_per_step = (time.time() - start_time) / steps\n",
    "                print('\\rEpisode {}\\tSteps: {}\\tTime per step: {:.6f}\\tAverage Scores: {:.3f}'\n",
    "                      .format(self.episode, steps, time_per_step, *average_scores), end=\"\")\n",
    "                last_print_time = time.time()\n",
    "            if self.episode % print_every == 0:\n",
    "                print(\"\\r\" + \" \" * 80, end=\"\")\n",
    "                print('\\rEpisode {}\\tAverage Scores: {:.3f}'.format(self.episode, *average_scores))\n",
    "            if len(self.scores) >= print_every and np.max(average_scores) >= goal:\n",
    "                print('\\nEnvironment solved in {:d} episodes!\\tAverage Score: {:.2f}\\tTime elapsed: {}'.format(\n",
    "                    self.episode, np.max(average_scores), time.time() - start_time))\n",
    "                break\n",
    "\n",
    "    def test_agent(self, n_episodes, max_t):\n",
    "        for _ in range(n_episodes):\n",
    "            self.myenv.reset()\n",
    "            states = self.myenv.get_observations(behavior_index=0)\n",
    "            score = np.zeros(len(self.ddpg_agents))\n",
    "            for _ in range(max_t):\n",
    "                # get actions from all agents:\n",
    "                actions = self.ddpg_agents.act(convert_to_tensor(states[:, np.newaxis, :]), noise_scale=0.0)\n",
    "                # remove batch_size from actions:\n",
    "                actions = actions[:, 0, :]\n",
    "\n",
    "                self.myenv.set_actions(behavior_index=0, continuous=actions)\n",
    "                self.myenv.step()\n",
    "                next_states, rewards, dones = self.myenv.get_experiences(behavior_index=0)\n",
    "\n",
    "                score += rewards.squeeze()\n",
    "                states = next_states\n",
    "                if np.any(dones):  # exit loop if episode finished\n",
    "                    break\n",
    "            print(\"Score: {}\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "random_seed = 1\n",
    "np.random.seed(random_seed)\n",
    "torch.manual_seed(random_seed)\n",
    "random.seed(random_seed)\n",
    "train_env = MyUnityEnvironment(file_name=ENV_FILE_NAME, seed=random_seed, no_graphics=True, worker_id=0)\n",
    "train_env.set_timescale(time_scale=100.0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "actor1 = Actor(state_size=8, action_size=2, hidden_layer_sizes=[400, 300], activation_func=f.leaky_relu)\n",
    "critic1 = Critic(state_size=8, action_size=2, hidden_layer_sizes=[400, 300], activation_func=f.leaky_relu,\n",
    "                 inject_layer=0)\n",
    "ddpg_agent1 = DDPGAgent(actor1, critic1, gamma=0.99, tau=1.0e-3, lr_actor=1.0e-4, lr_critic=1.0e-3, weight_decay=1.0e-2)\n",
    "ddpg_agent_list = [ddpg_agent1]\n",
    "ddpg_agents = DDPGAgents(ddpg_agent_list)\n",
    "ddpg_agents_tester = DDPGAgentsTester(ddpg_agents, train_env, buffer_size=int(1.0e6), noise_start=1.0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "You can skip this cell, if you don’t want to train the agent from scratch. It may take 30 to 45 minutes:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0\tAverage Scores: 1.500                                                 \n",
      "Episode 1000\tAverage Scores: 0.854                                              \n",
      "Episode 2000\tAverage Scores: 0.710                                              \n",
      "Episode 3000\tAverage Scores: 0.829                                              \n",
      "Episode 4000\tAverage Scores: 1.844                                              \n",
      "Episode 5000\tAverage Scores: 2.710                                              \n",
      "Episode 6000\tAverage Scores: 3.985                                              \n",
      "Episode 6301\tSteps: 182838\tTime per step: 0.011439\tAverage Scores: 10.000\n",
      "Environment solved in 6301 episodes!\tAverage Score: 10.00\tTime elapsed: 2091.4249007701874\n"
     ]
    }
   ],
   "source": [
    "ddpg_agents_tester.myenv = train_env\n",
    "ddpg_agents_tester.train_agents(n_episodes=int(1.0e5), max_t=100, goal=10.0, update_every=1,\n",
    "                                num_updates=1, batch_size=64, noise_decay=6.93e-6)\n",
    "ddpg_agents.save_checkpoint(filename=CHECKPOINT_FILENAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_scores():\n",
    "    scores = np.vstack(ddpg_agents_tester.scores)\n",
    "    scores = np.max(scores, 1)\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    plt.plot(np.arange(1, len(scores) + 1), scores)\n",
    "    plt.ylabel('Score')\n",
    "    plt.xlabel('Episode #')\n",
    "    plt.show()\n",
    "\n",
    "plot_scores()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Watch a Smart Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_env = MyUnityEnvironment(file_name=ENV_FILE_NAME, worker_id=1)\n",
    "test_env.set_timescale(1.0)\n",
    "test_env.set_display_size(width=DISPLAY_SIZE[0], height=DISPLAY_SIZE[1])\n",
    "ddpg_agents_tester.myenv = test_env\n",
    "ddpg_agents.load_checkpoint(filename=CHECKPOINT_FILENAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: [20.0000003]\n",
      "Score: [20.0000003]\n",
      "Score: [20.0000003]\n",
      "Score: [20.0000003]\n",
      "Score: [20.0000003]\n",
      "Score: [20.0000003]\n",
      "Score: [20.0000003]\n",
      "Score: [20.0000003]\n",
      "Score: [20.0000003]\n",
      "Score: [20.0000003]\n"
     ]
    }
   ],
   "source": [
    "ddpg_agents_tester.test_agent(n_episodes=10, max_t=200)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "When finished, you can close the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_env.close()\n",
    "test_env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "rl39",
   "language": "python",
   "display_name": "rl39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}